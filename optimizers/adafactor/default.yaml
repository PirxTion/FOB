# Warmup + Adafactor
optimizer:
  name: adafactor       # same as folder name
  learning_rate: 1.e-3
  one_minus_beta1: 0.1  # 1 - beta1 parameter
  warmup_factor: 0.01   # factor of the total steps used for warmup
  weight_decay: 0.01    # parameter
  eps1: 1.0e-30
  eps2: 1.0e-3
  clipping_threshold: 1.0
  decay_rate: -0.8
  lr_interval: step     # epoch is possible but step is preferred
  eta_min_factor: 0.01  # the minimum learning rate of the cosine annealing given as a factor of the initial learning rate
  lr_scheduler: cosine  # can be either 'cosine' or 'poly'
  lr_power: 1.0         # only used if lr_scheduler == 'poly'
