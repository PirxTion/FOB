engine:
  accelerator: gpu
  data_dir: ./data
  deterministic: warn  # 'warn' tries to use deterministic algorithms if possible, also accepts true or false.
  # devices: 1
  log_extra: false
  optimize_memory: false
  output_dir: ./experiments
  precision: bf16-mixed  # floating precision of training, see https://lightning.ai/docs/pytorch/stable/common/precision_basic.html
  resume: null  # you can pass the path to your checkpoint here
  run_scheduler: sequential
  seed: 42
  seed_mode: fixed
  silent: false
  test_only: false
  workers: 16
