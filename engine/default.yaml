engine:
  accelerator: gpu           # whether to train on cpu or gpu
  data_dir: ./data           # where you want to store the training data
  deterministic: warn        # 'warn' tries to use deterministic algorithms if possible, also accepts true or false.
  # devices: 1               # this is set by each task by default, but can be overridden
  log_extra: false           # activate logging of gradients and more.
  optimize_memory: false     # use nondeterministic, but memory-efficient algorithms for self-attention
  output_dir: ./experiments  # where you want to store the results
  precision: bf16-mixed      # floating precision of training, see https://lightning.ai/docs/pytorch/stable/common/precision_basic.html
  resume: false              # you can pass the path to your checkpoint here or set to true, which loads the last checkpoint.
  run_scheduler: sequential  # How to schedule the runs of the experiment. Currently only supports 'sequential'.
  seed: 42                   # the seed to use for the experiment
  seed_mode: fixed           # currently only supports 'fixed'
  silent: false              # whether to hide progress bars. Recommended when writing outputs to a log file.
  test_only: false           # do not train the model before evaluation. Recommended to use with 'resume'.
  workers: 16                # the number of processes to use for dataloading
